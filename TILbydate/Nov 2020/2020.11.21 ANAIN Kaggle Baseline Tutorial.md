# 2020.11.21 ANAIN Kaggle Baseline Tutorial 

### Riiid competition Webinar with GM by Youhan Lee

* Kaggle의 주요 수익원은 대회 개최(진짜 B2B 똑똑한 듯 ㅋㅋ) 
* ROC-AUC Score (Rank-based matrix)
  * 참고: [링크](https://m.blog.naver.com/PostView.nhn?blogId=sw4r&logNo=221015817276&proxyReferer=https:%2F%2Fwww.google.com%2F)
  * target label 할 필요 없다. 실제 제출해야 하는 것이 무엇인지 matrix를 잘 보아야 한다..
* 제출 방식
  * notebook 제출: 커널에서 직접 제출한다.
    * time series 이므로, data leakage를 방해할 수 있어 API 제공함.

* 시계열(time series)에서는 시점을 언제로 잡느냐가 중요한 문제이다.
* 트레이닝은 어떻게?
  * AWS 상에서 트레이닝 -> 자신의 모델을 업로드 -> 캐글의 API에 올려 inference 실행
  * 또는 캐글 내에서 학습을 진행하고 바로 prediction을 할 수 있음
  * 학습하고 inference하는 것은 시간이 많이 걸림 -> ensemble하는 시간을 확보하려면 aws 상에서 트레이닝하고 이후에 upload
  * Amazon Sagemaker
* Strategies
  * Feature engineering 기반 shallow learning
    * 지문이 주어지지 않아서 pass?
    * 관련 강의를 들은 이력?
    * 본인의 오답률이 높은 카테고리?
  * 이전에 치뤘던 history 기반해서 feature 생성한다.
    * 이전에 문제 맞춘 이력에 기반해서 피쳐한다 (ex. Answer Accuracy History)
    * 어떤 질문이 많이 나왔는지 (ex. Frequency)
  * 다양한 아키텍쳐를 사용한 딥 러닝
    * 케라스의 Sequential model (seq2seq, transformer, lstm...)
    * null data가 몇개 있나? (null == -1)

* Cross Validation Strategies 어떻게
  * time series라면 지식은 축적되므로 time 순서로 하는 것이 아무래도 시간 패턴을 유지하면서 학습하여 안전할 것이다.
  * But, 절대 시작 시간이 아니고 사용자 별로 record 길이가 서로 제각각이다.
* 추천 노트북
  * CV Strategy (its7171/cv-strategy)
  * Baseline (its7171/lgbm-with-loop-feature-engineering)
  * Submission (its7171/time-series-api-iter-test-emulator)
* 대회를 잘 하고 싶으면 대회 자체를 tracking해서 사람들의 점수 변화를 유추해보자.
* 데이터가 너무 크다. 빠르게 읽고 처리를 해야 한다.
  * kaggle.com/rohanrao/tutorial-on-reading-larget-datasets
  * kaggle.com/andradaolteanu/answer-correctness-rapids-xgb-lgbm
  * Pandas는 느리고 NumPy는 빠르다. 뭐 이런 꿀팁을 가져가자.
  * GPU 기반으로 가즈아. 없으면 kaggle/colab/Rapids AI 사용하자.

* 추천 대회
  * 2019 Data Science Bowl (특정 어린이 대상 교육 앱이 있는데 로그 데이터를 줄 테니까 어린 아이가 나중에 특정 문제를 맞출 지 안 맞출 지 맞추면 된다)
  * Web Traffic Time Series Forecasting(2017, time series)
  * 주로 솔루션을 보고 아이디어를 차용하면 수월하게 메달을 딸 수 있다.
* 꿀팁
  * Shallow model * 딥러닝 모델 = 시너지가 크다.
  * 각을 잘 재야 한다?! 짬에서 나오는 것인데 특정 노트북이 나왔고 리더보드가 어떻게 변화하는 지 살펴봐야 한다. 왜인지 이 노트북에 섞으면 될 것 같다. 디스커션과 스코어를 보면서 트리모델 피쳐를 0.7로 만들고 딥러닝 모델...로 섞으면 0.8~0.9네. 바로 메달감 올라가겠다.. 기민하게 영리하게 대처한다.
  * Discussion과 Notebook을 주로 봐야 한다. 좋은 노트북은 필사하도록 한다.
* 앙상블이 키다!
  * Feature 셋을 다양성으로 얻는다.
  * 모델을 다양하게 얻는다.
  * leaderboard 스코어 / cross validation score / simple average / rank-based average
* 캐글에서 다루는 부분
  * EDA
  * 인사이트
  * 피쳐 생성
  * 모델 개발
  * 모델 평가/피쳐 성능 확인
  * Discussion/Kernel 참고
* 캐글에서 다루지 않는 부분
  * 문제 설정
  * 데이터 수집
  * 데이터 전처리 (조금 할 때도 있지만, 사실상 다 해서 준다...)
* 캐글 (머신러닝 대회) 만한 공부방법이 없다.
  * 공지사항이나 discussion 참고
  * knowledge tracking... 이라는 키워드가 있으면 그냥 계속 구글링해서 찾아보고 공부한다.
  * 첫 문서를 통해서 복리를 통해 공부하는 내용을 쌓아가자.