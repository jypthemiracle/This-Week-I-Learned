# 2020.05.28 Honux 수업

## S3

* 내구성 > 가용성
* 데이터 특성에 알맞는 스토리지 서비스를 선택한다.
* 1 EC2: N EBS (1 컴퓨터: N 하드디스크)
* NAS의 반대 개념 느낌이다.
* 매우 높은 가용성. 리전 별로 분리하여 저장한다.
* DevOps 저장소 + 실제 스토리지 서비스 + artifact 등등
* Public으로서, Private으로서 모두 사용할 수 있다.
* 같은 리전 내의 다른 서비스들간의 트래픽 요금은 무료!
  * EC2 <-> S3
  * IAM Role을 통하여 EC2가 S3에 접근할 수 있는 방법도 제공한다.
* 폴더 개념은 없고 prefix만 존재한다.
* Key를 기반으로 객체 분산하므로 prefix가 유사하면 성능이 저하되지만 이제 개선되었다.
  * 인간은 맨 끝의 폴더 이름만 바꾼다.
  * 최악의 경우에는 최상위 prefix에 해쉬 문자열을 넣는다. 성능이 개선된다.
* Presigned URL
  * 임시적인 권한 설정
  * URL을 갖고 있는 익명 다수 사용자에게 업로드 또는 다운로드 권한 부여 가능(만료 시간 지정 가능)
* 마지막 주소에 ```?torrent``` 를 붙이면 P2P 기반 토렌트 파일이 나오니까 요금을 절약할 수 있다.
* Storage Class ~ 접근 비용

| Storage class           | Designed for                                                 | Durability (designed for) | Availability (designed for)        | Availability Zones | Min storage duration | Min billable object size | Other considerations                                         |
| :---------------------- | :----------------------------------------------------------- | :------------------------ | :--------------------------------- | :----------------- | :------------------- | :----------------------- | :----------------------------------------------------------- |
| S3 Standard             | Frequently accessed data                                     | 99.999999999%             | 99.99%                             | >= 3               | None                 | None                     | None                                                         |
| S3 Standard-IA          | Long-lived, infrequently accessed data                       | 99.999999999%             | 99.9%                              | >= 3               | 30 days              | 128 KB                   | Per GB retrieval fees apply.                                 |
| S3 Intelligent-Tiering  | Long-lived data with changing or unknown access patterns     | 99.999999999%             | 99.9%                              | >= 3               | 30 days              | None                     | Monitoring and automation fees per object apply. No retrieval fees. |
| S3 One Zone-IA          | Long-lived, infrequently accessed, non-critical data         | 99.999999999%             | 99.5%                              | 1                  | 30 days              | 128 KB                   | Per GB retrieval fees apply. Not resilient to the loss of the Availability Zone. |
| S3 Glacier              | Long-term data archiving with retrieval times ranging from minutes to hours | 99.999999999%             | 99.99% (after you restore objects) | >= 3               | 90 days              | 40 KB                    | Per GB retrieval fees apply. You must first restore archived objects before you can access them. For more information, see [Restoring Archived Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/restoring-objects.html). |
| S3 Glacier Deep Archive | Archiving rarely accessed data with a default retrieval time of 12 hours | 99.999999999%             | 99.99% (after you restore objects) | >= 3               | 180 days             | 40 KB                    | Per GB retrieval fees apply. You must first restore archived objects before you can access them. For more information, see [Restoring Archived Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/restoring-objects.html). |
| RRS (Not recommended)   | Frequently accessed, non-critical data                       | 99.99%                    | 99.99%                             | >= 3               | None                 | None                     | None                                                         |

## Amazon Glacier

* 1GB - 1 cent
* 성능을 희생하므로 매우 느리다.
* Amazon Virtual Tape
* S3 -> Glacier(주기적으로 넣어주는 옵션) -> 요청시 이관 S3

## Amazon Snowball

* 대형 데이터를 고속으로 처리한다.
* 통신으로 하면 영원히 끝나지 않으니 물리적으로 처리한다.

## AWS Storage Gateway

* 초고속 통신이 가능한 전용선을 아예 연결해버린다.
* 삼성전자, 네이버 수준의 기업 규모를 가져야 사용이 가능하다.

## 데이터 기준

* 다른 데이터 없이 다시 만들 수 있느냐를 기준으로 한다.
  * 계속 저장 vs 잠깐 저장
  * 깨지면 절대 안되는 것 vs 깨져도 되는가? 덜 크리티컬한가? 유효기간이 있느냐? (시간의 흐름 순)

하드 디스크 annual failure rate 15%

0.15 * 0.15 = 2 Copy failure rate == 0.1%

3 copy가 제일 안전하고 현실적인 방법

결국 하둡! 안전하게 분산시스템 만들자. 전체 저장소가 하나의 저장소처럼 보인다. (3 copy 보장)

* Fault-Tolerant
  * PBFT 2n+1
  * 아 다까먹었네 ^^ㄷ
* Redis - 홀수개 유지

* 핫 데이터 - 자주 쓰는 데이터
  * LRU Cache - 하나가 사용되었으면 그 데이터 포함 주변의 데이터가 자주 사용된다.
* 콜드 데이터 - 자주 쓰지 않는 데이터
  * 개인정보 보호데이터
* 10:90 이론
  * 10%의 핫 데이터가 90%의 접근을 커버한다.
  * 90%의 콜드 데이터가 10%의 접근도 커버하지 못한다.

## References

https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html